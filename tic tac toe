{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNtWUw/oXfJVz1hYkPgXnQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vi-c-hu/RL/blob/main/tic%20tac%20toe\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sUnqMU8_kpO",
        "outputId": "1d35633f-16b7-4fa9-8509-4adc55b75fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are playing against the trained agent (X)\n",
            "X |   |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "Enter your move (0-8): 3\n",
            "X |   |  \n",
            "--+---+--\n",
            "O |   |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "X | X |  \n",
            "--+---+--\n",
            "O |   |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "Enter your move (0-8): 2\n",
            "X | X | O\n",
            "--+---+--\n",
            "O |   |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "X | X | O\n",
            "--+---+--\n",
            "O | X |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "Enter your move (0-8): 1\n",
            "X | X | O\n",
            "--+---+--\n",
            "O | X |  \n",
            "--+---+--\n",
            "  |   |  \n",
            "X | X | O\n",
            "--+---+--\n",
            "O | X |  \n",
            "--+---+--\n",
            "O |   |  \n",
            "Enter your move (0-8): 5\n",
            "X | X | O\n",
            "--+---+--\n",
            "O | X | X\n",
            "--+---+--\n",
            "O |   |  \n",
            "X | X | O\n",
            "--+---+--\n",
            "O | X | X\n",
            "--+---+--\n",
            "O | O |  \n",
            "Enter your move (0-8): 7\n",
            "X | X | O\n",
            "--+---+--\n",
            "O | X | X\n",
            "--+---+--\n",
            "O | O |  \n",
            "X | X | O\n",
            "--+---+--\n",
            "O | X | X\n",
            "--+---+--\n",
            "O | O | X\n",
            "Winner: X\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define the Tic-Tac-Toe environment\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = [' '] * 9\n",
        "        self.current_player = 'X'\n",
        "        self.winner = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = [' '] * 9\n",
        "        self.current_player = 'X'\n",
        "        self.winner = None\n",
        "\n",
        "    def make_move(self, action):\n",
        "        if self.board[action] == ' ' and not self.winner:\n",
        "            self.board[action] = self.current_player\n",
        "            self.check_winner()\n",
        "            self.switch_player()\n",
        "\n",
        "    def switch_player(self):\n",
        "        self.current_player = 'X' if self.current_player == 'O' else 'O'\n",
        "\n",
        "    def check_winner(self):\n",
        "        winning_combinations = [\n",
        "            (0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
        "            (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
        "            (0, 4, 8), (2, 4, 6)\n",
        "        ]\n",
        "        for a, b, c in winning_combinations:\n",
        "            if self.board[a] == self.board[b] == self.board[c] != ' ':\n",
        "                self.winner = self.board[a]\n",
        "\n",
        "    def is_game_over(self):\n",
        "        return ' ' not in self.board or self.winner\n",
        "\n",
        "    def get_state(self):\n",
        "        return tuple(self.board)\n",
        "\n",
        "# Q-Learning agent\n",
        "class QLearningAgent:\n",
        "    def __init__(self, epsilon=0.1, alpha=0.1, gamma=0.9):\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.q_table = {}\n",
        "        self.prev_state = None\n",
        "        self.prev_action = None\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if random.uniform(0, 1) < self.epsilon:\n",
        "            available_actions = [i for i, s in enumerate(state) if s == ' ']\n",
        "            return random.choice(available_actions) if available_actions else None\n",
        "        else:\n",
        "            if state in self.q_table:\n",
        "                available_actions = [i for i, s in enumerate(state) if s == ' ']\n",
        "                if available_actions:\n",
        "                    return max([(i, self.q_table[state][i]) for i in available_actions], key=lambda x: x[1])[0]\n",
        "                else:\n",
        "                    return None\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state, next_action):\n",
        "        if state not in self.q_table:\n",
        "            self.q_table[state] = [0.0] * 9\n",
        "        if next_state not in self.q_table:\n",
        "            self.q_table[next_state] = [0.0] * 9\n",
        "        if self.prev_state is not None:\n",
        "            self.q_table[self.prev_state][self.prev_action] += self.alpha * (\n",
        "                reward + self.gamma * self.q_table[state][action] - self.q_table[self.prev_state][self.prev_action]\n",
        "            )\n",
        "        self.prev_state = state\n",
        "        self.prev_action = action\n",
        "\n",
        "    def reset(self):\n",
        "        self.prev_state = None\n",
        "        self.prev_action = None\n",
        "\n",
        "# Training the Q-Learning agent\n",
        "def train_q_learning_agent(agent, env, episodes):\n",
        "    for episode in range(episodes):\n",
        "        state = env.get_state()\n",
        "        agent.reset()\n",
        "\n",
        "        while not env.is_game_over():\n",
        "            action = agent.choose_action(state)\n",
        "            if action is None:\n",
        "                break\n",
        "            env.make_move(action)\n",
        "            next_state = env.get_state()\n",
        "\n",
        "            if env.winner == 'X':\n",
        "                reward = 1\n",
        "            elif env.winner == 'O':\n",
        "                reward = -1\n",
        "            else:\n",
        "                reward = 0\n",
        "\n",
        "            next_action = agent.choose_action(next_state)\n",
        "            agent.update_q_table(state, action, reward, next_state, next_action)\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "        env.reset()\n",
        "\n",
        "# Play against the trained agent\n",
        "def play_vs_agent(agent, env):\n",
        "    while not env.is_game_over():\n",
        "        env.make_move(agent.choose_action(env.get_state()))\n",
        "        print_board(env.board)\n",
        "        if env.winner:\n",
        "            print(f'Winner: {env.winner}')\n",
        "            break\n",
        "        player_action = int(input('Enter your move (0-8): '))\n",
        "        env.make_move(player_action)\n",
        "        print_board(env.board)\n",
        "\n",
        "# Helper function to display the board\n",
        "def print_board(board):\n",
        "    print(board[0], '|', board[1], '|', board[2])\n",
        "    print('--+---+--')\n",
        "    print(board[3], '|', board[4], '|', board[5])\n",
        "    print('--+---+--')\n",
        "    print(board[6], '|', board[7], '|', board[8])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    agent = QLearningAgent()\n",
        "    env = TicTacToe()\n",
        "\n",
        "    # Train the Q-Learning agent\n",
        "    train_q_learning_agent(agent, env, episodes=10000)\n",
        "\n",
        "    # Play against the trained agent\n",
        "    print(\"You are playing against the trained agent (X)\")\n",
        "    while True:\n",
        "        play_vs_agent(agent, env)\n",
        "        play_again = input(\"Play again? (yes/no): \").strip().lower()\n",
        "        if play_again != \"yes\":\n",
        "            break\n",
        "7\n"
      ]
    }
  ]
}